{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uncertainty-Aware CheXpert Diagnosis - Exploration\n",
    "\n",
    "This notebook demonstrates the key components of the uncertainty-aware CheXpert diagnosis system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, str(Path.cwd().parent / 'src'))\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import yaml\n",
    "\n",
    "from uncertainty_aware_chexpert_diagnosis.data.loader import CheXpertDataModule\n",
    "from uncertainty_aware_chexpert_diagnosis.models.model import EvidentialCheXpertModel\n",
    "from uncertainty_aware_chexpert_diagnosis.evaluation.metrics import UncertaintyMetrics\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config\n",
    "config_path = Path.cwd().parent / 'configs' / 'default.yaml'\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"Configuration loaded successfully\")\n",
    "print(f\"Model architecture: {config['model']['architecture']}\")\n",
    "print(f\"Number of classes: {config['model']['num_classes']}\")\n",
    "print(f\"Uncertain policy: {config['data']['uncertain_policy']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Explore Data Distribution\n",
    "\n",
    "Analyze the distribution of certain vs uncertain labels in CheXpert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data module\n",
    "data_module = CheXpertDataModule(config)\n",
    "data_module.prepare_data()\n",
    "data_module.setup()\n",
    "\n",
    "print(f\"Training samples: {len(data_module.train_dataset)}\")\n",
    "print(f\"Validation samples: {len(data_module.val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze label distribution\n",
    "train_labels = data_module.train_dataset.labels\n",
    "train_uncertainty = data_module.train_dataset.uncertainty_masks\n",
    "\n",
    "label_names = config['data']['labels']\n",
    "\n",
    "# Compute statistics\n",
    "positive_counts = (train_labels > 0.7).sum(axis=0)\n",
    "negative_counts = (train_labels < 0.3).sum(axis=0)\n",
    "uncertain_counts = train_uncertainty.sum(axis=0)\n",
    "\n",
    "# Plot distribution\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "x = np.arange(len(label_names))\n",
    "width = 0.6\n",
    "\n",
    "axes[0].bar(x, positive_counts, width, color='green', alpha=0.7)\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Positive Labels')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(label_names, rotation=45, ha='right')\n",
    "\n",
    "axes[1].bar(x, negative_counts, width, color='red', alpha=0.7)\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_title('Negative Labels')\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels(label_names, rotation=45, ha='right')\n",
    "\n",
    "axes[2].bar(x, uncertain_counts, width, color='orange', alpha=0.7)\n",
    "axes[2].set_ylabel('Count')\n",
    "axes[2].set_title('Uncertain Labels')\n",
    "axes[2].set_xticks(x)\n",
    "axes[2].set_xticklabels(label_names, rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Total uncertain labels: {uncertain_counts.sum():.0f}\")\n",
    "print(f\"Percentage uncertain: {100 * uncertain_counts.sum() / (len(train_labels) * len(label_names)):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of samples\n",
    "train_loader = data_module.train_dataloader()\n",
    "batch = next(iter(train_loader))\n",
    "\n",
    "images = batch['image']\n",
    "labels = batch['label']\n",
    "uncertainty_masks = batch['uncertainty_mask']\n",
    "\n",
    "# Visualize first 4 samples\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx in range(4):\n",
    "    img = images[idx].permute(1, 2, 0).numpy()\n",
    "    # Denormalize\n",
    "    img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "    img = np.clip(img, 0, 1)\n",
    "    \n",
    "    axes[idx].imshow(img)\n",
    "    axes[idx].axis('off')\n",
    "    \n",
    "    # Add label information\n",
    "    label_info = []\n",
    "    for i, name in enumerate(label_names):\n",
    "        if uncertainty_masks[idx, i] > 0.5:\n",
    "            label_info.append(f\"{name}: Uncertain\")\n",
    "        elif labels[idx, i] > 0.7:\n",
    "            label_info.append(f\"{name}: Positive\")\n",
    "        elif labels[idx, i] < 0.3:\n",
    "            label_info.append(f\"{name}: Negative\")\n",
    "    \n",
    "    axes[idx].set_title('\\n'.join(label_info[:3]), fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Architecture Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = EvidentialCheXpertModel(config)\n",
    "model = model.to(device)\n",
    "\n",
    "total_params = model.get_num_params()\n",
    "trainable_params = model.get_num_trainable_params()\n",
    "\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"\\nModel architecture: {config['model']['architecture']}\")\n",
    "print(f\"Use evidential: {config['model']['use_evidential']}\")\n",
    "print(f\"Evidence activation: {config['model']['evidence_activation']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test forward pass\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    sample_images = images[:4].to(device)\n",
    "    outputs = model(sample_images)\n",
    "\n",
    "print(\"Model outputs:\")\n",
    "for key, value in outputs.items():\n",
    "    if isinstance(value, torch.Tensor):\n",
    "        print(f\"  {key}: shape {value.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Uncertainty Visualization\n",
    "\n",
    "Visualize epistemic and aleatoric uncertainty for sample predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions for a batch\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(images.to(device))\n",
    "    \n",
    "    probs = outputs['prob'].cpu().numpy()\n",
    "    epistemic = outputs['epistemic'].cpu().numpy() if 'epistemic' in outputs else None\n",
    "    aleatoric = outputs['aleatoric'].cpu().numpy() if 'aleatoric' in outputs else None\n",
    "\n",
    "if epistemic is not None and aleatoric is not None:\n",
    "    # Plot uncertainty decomposition\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # Epistemic uncertainty\n",
    "    axes[0].hist(epistemic, bins=30, color='blue', alpha=0.7, edgecolor='black')\n",
    "    axes[0].set_xlabel('Epistemic Uncertainty')\n",
    "    axes[0].set_ylabel('Frequency')\n",
    "    axes[0].set_title('Distribution of Epistemic Uncertainty')\n",
    "    axes[0].axvline(epistemic.mean(), color='red', linestyle='--', label=f'Mean: {epistemic.mean():.3f}')\n",
    "    axes[0].legend()\n",
    "    \n",
    "    # Aleatoric uncertainty\n",
    "    axes[1].hist(aleatoric, bins=30, color='green', alpha=0.7, edgecolor='black')\n",
    "    axes[1].set_xlabel('Aleatoric Uncertainty')\n",
    "    axes[1].set_ylabel('Frequency')\n",
    "    axes[1].set_title('Distribution of Aleatoric Uncertainty')\n",
    "    axes[1].axvline(aleatoric.mean(), color='red', linestyle='--', label=f'Mean: {aleatoric.mean():.3f}')\n",
    "    axes[1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Scatter plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(epistemic, aleatoric, alpha=0.6, c=probs.mean(axis=1), cmap='viridis')\n",
    "    plt.colorbar(label='Mean Prediction Probability')\n",
    "    plt.xlabel('Epistemic Uncertainty')\n",
    "    plt.ylabel('Aleatoric Uncertainty')\n",
    "    plt.title('Epistemic vs Aleatoric Uncertainty')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Uncertainty outputs not available (evidential mode disabled)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Prediction Examples with Uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show predictions with uncertainty for first 4 samples\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx in range(4):\n",
    "    # Plot probabilities\n",
    "    x = np.arange(len(label_names))\n",
    "    axes[idx].bar(x, probs[idx], color='steelblue', alpha=0.7)\n",
    "    axes[idx].set_xticks(x)\n",
    "    axes[idx].set_xticklabels(label_names, rotation=45, ha='right')\n",
    "    axes[idx].set_ylabel('Probability')\n",
    "    axes[idx].set_ylim([0, 1])\n",
    "    \n",
    "    # Add uncertainty information if available\n",
    "    if epistemic is not None:\n",
    "        title = f\"Sample {idx+1}\\nEpistemic: {epistemic[idx]:.3f}, Aleatoric: {aleatoric[idx]:.3f}\"\n",
    "    else:\n",
    "        title = f\"Sample {idx+1}\"\n",
    "    \n",
    "    axes[idx].set_title(title, fontsize=10)\n",
    "    axes[idx].axhline(y=0.5, color='red', linestyle='--', alpha=0.3)\n",
    "    axes[idx].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Key Innovation: Uncertainty Correlation\n",
    "\n",
    "Demonstrate correlation between model uncertainty and radiologist uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if epistemic is not None:\n",
    "    # Compute average uncertainty per sample\n",
    "    radiologist_uncertainty = uncertainty_masks.numpy().mean(axis=1)\n",
    "    \n",
    "    # Scatter plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(radiologist_uncertainty, epistemic, alpha=0.6, s=50)\n",
    "    plt.xlabel('Radiologist Uncertainty (fraction of uncertain labels)')\n",
    "    plt.ylabel('Model Epistemic Uncertainty')\n",
    "    plt.title('Correlation between Radiologist and Model Uncertainty')\n",
    "    \n",
    "    # Add correlation coefficient\n",
    "    from scipy.stats import spearmanr\n",
    "    corr, p_value = spearmanr(radiologist_uncertainty, epistemic)\n",
    "    plt.text(0.05, 0.95, f\"Spearman Ï = {corr:.3f}\\np-value = {p_value:.4f}\",\n",
    "             transform=plt.gca().transAxes, fontsize=12,\n",
    "             verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "    # Add trend line\n",
    "    z = np.polyfit(radiologist_uncertainty, epistemic, 1)\n",
    "    p = np.poly1d(z)\n",
    "    x_line = np.linspace(radiologist_uncertainty.min(), radiologist_uncertainty.max(), 100)\n",
    "    plt.plot(x_line, p(x_line), \"r--\", alpha=0.8, linewidth=2)\n",
    "    \n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nCorrelation Interpretation:\")\n",
    "    print(f\"  Spearman correlation: {corr:.3f}\")\n",
    "    print(f\"  This {'validates' if corr > 0.3 else 'suggests improvement needed for'} our approach:\")\n",
    "    print(f\"  The model learns to be uncertain when radiologists are uncertain.\")\n",
    "else:\n",
    "    print(\"Evidential mode is disabled. Enable it in config to see uncertainty correlation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "1. Data distribution with uncertain labels\n",
    "2. Model architecture with evidential learning\n",
    "3. Uncertainty decomposition (epistemic vs aleatoric)\n",
    "4. Novel contribution: Learning to predict radiologist uncertainty\n",
    "\n",
    "Next steps:\n",
    "- Train the full model: `python scripts/train.py`\n",
    "- Evaluate on test set: `python scripts/evaluate.py`\n",
    "- Analyze ablation studies comparing different uncertainty policies"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
